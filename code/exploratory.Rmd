---
title: "Exploratory Spatial Data Analysis"
author: "Alessandro Samuel-Rosa"
date: "4 July 2016"
output: pdf_document
bibliography: /home/lgcs-mds/Dropbox/jabref/biblio.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Conventional Soil Map

The conventional soil map that we want to model and extrapolate to poorly accessible areas, taken as our 
target stochastic variable *C*, was submitted to a topology check. All gaps (n = 8) and invalid geometries 
(n = 17) were manually fixed, except for the misfit between the soil map boundary and the boundary of the 
accessible area. The resulting, topologically correct, soil map is shown below.

```{r}
# Load soil map
soil_map <- raster::shapefile("/home/lgcs-mds/projects/urucu/data/vector/MCS_Simplif_Poligon_correct.shp")
soil_map$UM <- as.factor(soil_map$UM)
map <- sp::spplot(
  soil_map, "UM", col.regions = c("firebrick1", "deepskyblue", "lightgray", "khaki"), col = NA,
  main = "Conventional target soil map", aspect = "iso", scales = list(draw = TRUE))
names(map$legend) <- "inside"
map$legend$inside$x <- 0.50
map$legend$inside$y <- 0.15
map$legend$inside$args$key$space <- "left"
map
```

The area covered by each soil mapping unit in the target conventional soil map is show below. Mapping unit 
CXal has the largest area, while PACd has the smallest area.

```{r}
soil_map_areas <- data.frame(area = rgeos::gArea(soil_map, byid = TRUE), um = soil_map$UM)
soil_map_areas$area <- soil_map_areas$area / 10000
barplot(c(by(soil_map_areas$area, soil_map_areas$um, sum)),
        main = "Area of each mapping unit (ha)")
```

# Field Calibration Points

The database contains three datasets with field soil calibration data. The first is composed of data
from n = 119 complete soil profile description. The second contains soil data from n = 199 boreholes,
one of which lies outside the accessible area. Both of these datasets were used as calibration soil
data to build the conventional soil map. The third dataset is composed of soil data from n = 66 
boreholes. This last dataset was originally used for validating the conventional soil map.

```{r}
# Load accessible area
area <- raster::shapefile("/home/lgcs-mds/projects/urucu/data/vector/Lim10000Detal.shp")

# Complete soil profile descriptions (n = 119)
profiles <- raster::shapefile("/home/lgcs-mds/projects/urucu/data/vector/Perfis.shp")
sp::spplot(
  area, 1, aspect = "iso", scales = list(draw = TRUE), colorkey = FALSE, col.regions = "gray",
  main = "Complete soil profile descriptions (n = 119)",
  panel = function(x, y, ...) {
    sp::panel.polygonsplot(x, y, ...)
    lattice::panel.points(sp::coordinates(profiles), pch = 21, cex = 0.5)
    })

# Borehole soil descriptions (n = 199)
# Identify point lying outside the accessible area
boreholes <- raster::shapefile("/home/lgcs-mds/projects/urucu/data/vector/Tradagens.shp")
in_or_out <- which(is.na(sp::over(boreholes, area)$OBJECTID))
sp::spplot(
  area, 1, aspect = "iso", scales = list(draw = TRUE), colorkey = FALSE, col.regions = "gray",
  main = "Borehole soil descriptions (n = 199)",
  panel = function(x, y, ...) {
    sp::panel.polygonsplot(x, y, ...)
    lattice::panel.points(sp::coordinates(boreholes), pch = 21, cex = 0.5)
    lattice::panel.points(sp::coordinates(boreholes[in_or_out, 1:2]), pch = 20, cex = 0.5, col = "red")
    })

# Boreholes used for validation (n = 66)
validation <- raster::shapefile("/home/lgcs-mds/projects/urucu/data/vector/Tradagens_Validacao.shp")
sp::spplot(
  area, 1, aspect = "iso", scales = list(draw = TRUE), colorkey = FALSE, col.regions = "gray",
  main = "Boreholes used for validation (n = 66)",
  panel = function(x, y, ...) {
    sp::panel.polygonsplot(x, y, ...)
    lattice::panel.points(sp::coordinates(validation), pch = 21, cex = 0.5)
    })
```

For the purpose of our study, I propose removing the point lying outside the accessible area. Merging the 
three datasets would result in a final calibration dataset with n = 383 points.

```{r}
# Field calibration dataset (n = 383)
field <- 
  as.data.frame(
    rbind(sp::coordinates(profiles), sp::coordinates(boreholes)[-in_or_out, ], 
          sp::coordinates(validation)))
sp::coordinates(field) <- ~ coords.x1 + coords.x2
sp::proj4string(field) <- sp::proj4string(profiles)
sp::spplot(
  area, 1, aspect = "iso", scales = list(draw = TRUE), colorkey = FALSE, col.regions = "gray",
  main = "Field calibration dataset (n = 383)",
  panel = function(x, y, ...) {
    sp::panel.polygonsplot(x, y, ...)
    lattice::panel.points(sp::coordinates(field), pch = 21, cex = 0.5)
    })
```

The number of field calibration sample points in each soil mapping unit us shown below.

```{r}
field_cal <- sp::over(field, soil_map)
plot(field_cal$UM, ylim = c(0, 180), main = "Points per mapping unit", cex.axis = 0.8)
text(1:4, summary(field_cal$UM) + 10, summary(field_cal$UM))
```

# Random Calibration Points

In one of the scenarios that we simulate, the conventional target soil map is all that we have available. In 
order to model it and extrapolate its spatial structure to poorly accessible areas, we use a stratified random
sample composed of n ~ 2000 points.

```{r}
# Stratified random sample (n ~ 2000)
set.seed(2001)
random <- sp::spsample(soil_map, n = 2000, type = "stratified")
sp::spplot(
  area, 1, aspect = "iso", scales = list(draw = TRUE), colorkey = FALSE, col.regions = "gray",
  main = "Stratified random sample (n ~ 2000)",
  panel = function(x, y, ...) {
    sp::panel.polygonsplot(x, y, ...)
    lattice::panel.points(sp::coordinates(random), pch = 21, cex = 0.1)
    })
```

The resulting number of sample points allocated in each soil mapping unit is shown below. The larger the area
covered by a mapping unit, the larger the number of sample points.

```{r}
random_cal <- sp::over(random, soil_map)
plot(random_cal$UM, ylim = c(0, 1000), main = "Points per mapping unit")
text(1:4, summary(random_cal$UM) + 50, summary(random_cal$UM))
```

# Expert Calibration Points

The last calibration dataset is composed of soil data from n = 847 points manually located by an expert on the
computer screen. The spatial distribution of these sample points is shown below.

```{r}
# Expert calibration points (n = 847)
expert <- raster::shapefile("/home/lgcs-mds/projects/urucu/data/vector/Trein_Classes.shp")

# See how many are outside the accessible area
in_or_out <- sp::over(expert, area)
sp::spplot(
  area, 1, aspect = "iso", scales = list(draw = TRUE), colorkey = FALSE, col.regions = "gray",
  main = "Expert calibration points (n = 847)",
  panel = function(x, y, ...) {
    sp::panel.polygonsplot(x, y, ...)
    lattice::panel.points(sp::coordinates(expert), pch = 21, cex = 0.5)
    lattice::panel.points(sp::coordinates(expert[which(is.na(in_or_out$OBJECTID)), ]),
                          pch = 20, cex = 0.5, col = "red")
    
    })
in_or_out <- length(which(is.na(in_or_out$OBJECTID))) / length(in_or_out$OBJECTID)
```

This dataset has some features that require our attention. First, `r round(in_or_out * 100)` percent of the 
points lie outside the accessible area (red points above). Second, the expert assigned the sample points to
five classes, while our target variable (the conventional soil map) has only four classes (mapping units). A
visual inspection of the soil map and classes attributed to the sample points suggest that classes 2 and 3 are 
equivalent to GXvd.

```{r}
sp::spplot(
  soil_map, "UM", aspect = "iso", scales = list(draw = FALSE), colorkey = FALSE, 
  col.regions = c("firebrick1", "deepskyblue", "lightgray", "khaki"), col = NA,
  main = "Zoom in the expert calibration points", ylim = c(9460143, 9461942), xlim = c(240125, 243075),
  panel = function(x, y, ...) {
    sp::panel.polygonsplot(x, y, ...)
    lattice::panel.points(sp::coordinates(expert), pch = 20)
    lattice::panel.text(sp::coordinates(expert)[, 1], sp::coordinates(expert)[, 2], 
                        expert@data$MDS, pos = 2)
    })
```

If the match between attributes classes and my guesses are correct, then we can compute the number of points
per mapping unit. Again, the number of points is correlated with the area of the mapping unit.

```{r}
expert$UM <- as.factor(expert$MDS)
levels(random_cal$UM)
levels(expert$UM) <- levels(random_cal$UM)[c(1, 2, 2, 3, 4)]
plot(expert$UM, ylim = c(0, 320), main = "Points per mapping unit")
text(1:4, summary(expert$UM) + 25, summary(expert$UM))
```

\newpage

# Covariates

There are p = 11 covariates in the database: elevation,  slope,  curvature, plan curvature, profile curvature,
downslope flow length, upslope flow length, flow accumulation, flow direction, aspect and topographic wetness
index. All covariate data in my possession matches the description presented by @Villela2013. However, there 
are some details worth mentioning regarding the data structure and the selection of the covariates.

## Aspect and flow direction data

It appears that the **aspect** data was used as is, i.e. without linearising its values. Linearisation is 
necessary because aspect is a circular variable: its minimum (0ยบ) and maximum (360ยบ) values have the 
same physical meaning. Linearisation can be done using the following equation:

$$northerness = |180 - aspect|$$

were **northerness** is a variable that indicates the degree of exposition of a surface to the north. Another 
solution is to transform the aspect data to categories, i.e. classes of orientation. It is not clear in the
thesis if the aspect data was used as a continuous or as a categorical covariate.

The reason for using aspect as a covariate is the hypothesis that it could determine the availability of water
in the environment. I am not sure if this holds for the Amazon region, specially in a study area with a range
in elevation values of 46-84 m. In general, aspect data has a marked influence on soil and other environmental
features in higher latitudes, beyond the tropics. As such, I believe there is no pedological basis for using 
it as a covariate in our study: I suggest dropping it from our dataset.

It is not clear how **flow direction** data was used in the analysis. It appears that this covariate was used
as is, i.e. taking its finite set of eight integer values (1, 2, 4, 8, 16, 32, 64, and 128) as a continuous
covariate, when the correct approach would be to use this covariate as a categorical covariate. However, like
aspect, I believe there is no pedological basis for using flow direction as a covariate in our study. Actually,
I think flow direction is used more to derive other, more pedologically sound, covariates, than as a covariate 
itself. As such, I suggest dropping flow direction from our dataset.

Finally, the northerness data gives evidence of the presence of (possibly spurious) depressions in the digital
elevation model at places of high elevation (see figure bellow). I believe that these depressions were created
due to the presence of contour lines with erroneous elevation values at some of the higher parts of the
landscape. As such, higher elevations may present high values of the topographic wetness index. These 
depressions in the digital elevation model could represent true, existing depressions. However, I am not aware
of the existence of such depressions at higher elevations in the study area.

![Artefacts in elevation data as suggested by northerness data. The transect (red line) shows the change in 
elevation values in a depression. ](~/projects/urucu/res/fig/north_sinks.png)

## Curvature data

Three covariates describing the landscape curvature were used in the study: horizontal, vertical and compound.
Because these covariates describe very similar features of the landscape, their correlation is generally very 
high. As a consequence, it is common to use only one of them as a covariate in soil prediction models. 
Eliminating redundant covariates is an important step in model calibration to avoid the undesirable 
consequences of multicollinearity. Stepwise procedures are inefficient in dealing with multi-collinear 
covariates. Due to the multiple comparisons, stepwise procedures do not prevent a poor covariate from entering
the model -- the chance of including a covariate with low discriminatory power is much larger than 
significance level (5%). As such, I suggest using only **compound curvature** as a covariate in our study.

Curvature data gives further evidence for the presence of possibly spurious artefacts in the digital elevation
model (see figure below). There is a considerable amount of noise in the form of stairs along the slopes 
resulting from the use of contour lines to generate the digital elevation model. This noise is a typical 
feature of digital elevation models produced using contour lines. In general, the solution is to use a 
smoothing filter to remove the noise from the digital elevation model before deriving terrain attributes. I am
not aware if or how these artefacts could damage the performance of our soil prediction models. However, it 
could be the reason for the noise (salt-and-pepper) observed in the spatial predictions made by @Villela2013,
which were later removed using a majority filter.

![Noise in curvature data caused by the use of contour lines to compute the digital elevation model. The 
solution is to use a smoothing filter to remove the noise from the digital elevation model before deriving 
terrain attributes.](~/projects/urucu/res/fig/curvature_contours.png)

## Flow length and accumulation

Covariates **flow accumulation** and **upslope flow path length** are strongly correlated, the difference
being that the latter is more efficient in highlighting larger water channels at the lowermost positions of 
the landscape. Despite of that, both are proxies of the same environmental condition: the potential that the
different parts of the landscape have of accumulating water. Being strongly correlated, it would be wise to
include only one of these three covariates in our soil prediction models. As such, I suggest we keep only that
with the largest pedological meaning and/or correlation with the dependent variable.

## Covariates to enter soil prediction models

I suggest we use the same set of covariates to enter our soil prediction models. Selection should be done 
using empirical evidence and pedological knowledge. Accordingly, the following set of covariates could be used:

* elevation
* slope
* downslope flow path length
* compound curvature
* flow accumulation or upslope flow path length
* topographic wetness index


